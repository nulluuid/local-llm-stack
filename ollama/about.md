# About

- [Ollama github](https://github.com/ollama/ollama)
- [Ollama site](https://ollama.com)
- [Ollama model library](https://ollama.com/library)
- [Ollama docs](https://github.com/ollama/ollama/tree/main/docs)
- [Ollama api docs](https://github.com/ollama/ollama/blob/main/docs/api.md)

# Quick start

- Start a server by running **docker compose up -d**
- Run a [**api.http**](api.http) (Use **httpyac**)
  - Download a model
  - Load the model to the memory
  - Generate a completion
  - Chat with the model
  - Chat with the model using a template
- Stop the server with **docker compose down**
